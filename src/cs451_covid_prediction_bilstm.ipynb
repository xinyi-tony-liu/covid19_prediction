{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cs451-covid-prediction-bilstm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueWyH6hDAtim"
      },
      "source": [
        "# CS451 Covid Prediction\n",
        "\n",
        "This notebook contains the group project solution for the cs451 final project, which aims to predict the spread of COVID-19 in Canada through usage of large quantities of Twitter data and other sources. The collection and sentiment analysis of Twitter data is performed separately, and is then used as an extra input alongside other covid-related data with the hopes of improving the model accuracy. We have chosen to implement the techniques outlined in a paper which boasts improvements on state-of-the-art techniques, including ARIMA, Simple Moving Average witha 6-day window, and Double Exponential Moving Average. Their technique uses a bidirectional LSTM and clusters countries by demographic, socioeconomic and health sector indicators to train the model on a richer dataset. We will include the Twitter sentiment analysis as an extra feature and see if this can improve the results even further."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6E4CHlqKnIoj"
      },
      "source": [
        "In order to expand our dataset for better accuracy, we performed K-Means clustering on countries using several demographic, socioeconomic and health sector indicators to find countries similar to Canada. We then collected data pertaining to the degree of lockdown measures for each country as supplemental features to our model. The data consists of:\n",
        "\n",
        "*   School closing:\n",
        "   * 0: No measures.\n",
        "   * 1: Safety precautions are required.\n",
        "   * 2: Recommended closing.\n",
        "   * 3: Require closing (only some levels/categories).\n",
        "   * 4: Require closing at all levels.\n",
        "*   Workplace closing:\n",
        "   * 0: No measures.\n",
        "   * 1: Safety precautions are required.\n",
        "   * 2: Recommended closing or working from home.\n",
        "   * 3: Require closing or working from home for some sectors or categories of workers.\n",
        "   * 4: Require closing for all sectors except for essential workplaces.\n",
        "*   Restrictions on gatherings:\n",
        "   * 0: No restrictions.\n",
        "   * 1: Restrictions on very large gatherings (limit > 1000 people).\n",
        "   * 2: Restrictions on gatherings between 101-1000 people.\n",
        "   * 3: Restrictions on gatherings between 11-100 people.\n",
        "   * 4: Restrictions on gatherings of 10 people or less.\n",
        "*   Public transport shutdown:\n",
        "   * 0: No restrictions.\n",
        "   * 1: Recommended closing or significantly reduce volume or routes or means of transportation available.\n",
        "   * 2: Require closing.\n",
        "*   International travel controls:\n",
        "   * 0: No restrictions.\n",
        "   * 1: Screening arrivals.\n",
        "   * 2: Quarantine arrivals from some or all regions.\n",
        "   * 3: Ban arrivals from some regions.\n",
        "   * 4: Ban on all regions or total border closure.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q34cXyZdfdZo"
      },
      "source": [
        "from datetime import date\n",
        "\n",
        "# Data for Canada was collected from https://www.cihi.ca/en/covid-19-intervention-timeline-in-canada\n",
        "# In case of discrepancy for certain measures between provinces, the most common date\n",
        "# of the measure implementation between the most populous provinces was selected.\n",
        "canada_lockdown_measures = {\n",
        "    'school-closing': [\n",
        "        (date(2020, 1, 23), 0),\n",
        "        (date(2020, 3, 17), 4),\n",
        "        (date(2020, 9, 8), 1),\n",
        "    ],\n",
        "    'workplace-closing': [\n",
        "        (date(2020, 1, 23), 0),\n",
        "        (date(2020, 3, 17), 3),\n",
        "        (date(2020, 3, 25), 4),\n",
        "        (date(2020, 5, 5), 3),\n",
        "    ],\n",
        "    'gatherings': [\n",
        "        (date(2020, 1, 23), 0),\n",
        "        (date(2020, 3, 16), 2),\n",
        "        (date(2020, 3, 27), 4),\n",
        "    ],\n",
        "    'public-transport': [\n",
        "        (date(2020, 1, 23), 0),\n",
        "    ],\n",
        "    'international-travel': [\n",
        "        (date(2020, 1, 23), 0),\n",
        "        (date(2020, 3, 16), 2),\n",
        "    ],\n",
        "}"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "id": "mKykINhQybf6",
        "outputId": "cbdd2b05-03e0-4744-a1e4-a0f0dc40c001"
      },
      "source": [
        "from datetime import timedelta\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def daterange(start_date, end_date, x):\n",
        "    for n in range(int((end_date - start_date).days)):\n",
        "        yield (start_date + timedelta(n), x)\n",
        "\n",
        "measures = ['school-closing', 'workplace-closing', 'gatherings', 'public-transport', 'international-travel']\n",
        "\n",
        "def generate_time_series(lockdown_measures):\n",
        "    end_date = date(2020, 12, 10)\n",
        "    data = {\n",
        "        'school-closing': [],\n",
        "        'workplace-closing': [],\n",
        "        'gatherings': [],\n",
        "        'public-transport': [],\n",
        "        'international-travel': [],\n",
        "    }\n",
        "    for measure in measures:\n",
        "        curr_date = date(2020, 1, 23)\n",
        "        curr_val = 0\n",
        "        for d, val in lockdown_measures[measure]:\n",
        "            data[measure] += list(daterange(curr_date, d, curr_val))\n",
        "            curr_date = d\n",
        "            curr_val = val\n",
        "        if curr_date < end_date:\n",
        "            data[measure] += list(daterange(curr_date, end_date, curr_val))\n",
        "    return data\n",
        "\n",
        "canada_data = generate_time_series(canada_lockdown_measures)\n",
        "canada_df = pd.DataFrame.from_dict(canada_data)\n",
        "canada_df"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>school-closing</th>\n",
              "      <th>workplace-closing</th>\n",
              "      <th>gatherings</th>\n",
              "      <th>public-transport</th>\n",
              "      <th>international-travel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(2020-01-23, 0)</td>\n",
              "      <td>(2020-01-23, 0)</td>\n",
              "      <td>(2020-01-23, 0)</td>\n",
              "      <td>(2020-01-23, 0)</td>\n",
              "      <td>(2020-01-23, 0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(2020-01-24, 0)</td>\n",
              "      <td>(2020-01-24, 0)</td>\n",
              "      <td>(2020-01-24, 0)</td>\n",
              "      <td>(2020-01-24, 0)</td>\n",
              "      <td>(2020-01-24, 0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(2020-01-25, 0)</td>\n",
              "      <td>(2020-01-25, 0)</td>\n",
              "      <td>(2020-01-25, 0)</td>\n",
              "      <td>(2020-01-25, 0)</td>\n",
              "      <td>(2020-01-25, 0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(2020-01-26, 0)</td>\n",
              "      <td>(2020-01-26, 0)</td>\n",
              "      <td>(2020-01-26, 0)</td>\n",
              "      <td>(2020-01-26, 0)</td>\n",
              "      <td>(2020-01-26, 0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(2020-01-27, 0)</td>\n",
              "      <td>(2020-01-27, 0)</td>\n",
              "      <td>(2020-01-27, 0)</td>\n",
              "      <td>(2020-01-27, 0)</td>\n",
              "      <td>(2020-01-27, 0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>317</th>\n",
              "      <td>(2020-12-05, 1)</td>\n",
              "      <td>(2020-12-05, 3)</td>\n",
              "      <td>(2020-12-05, 4)</td>\n",
              "      <td>(2020-12-05, 0)</td>\n",
              "      <td>(2020-12-05, 2)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>318</th>\n",
              "      <td>(2020-12-06, 1)</td>\n",
              "      <td>(2020-12-06, 3)</td>\n",
              "      <td>(2020-12-06, 4)</td>\n",
              "      <td>(2020-12-06, 0)</td>\n",
              "      <td>(2020-12-06, 2)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319</th>\n",
              "      <td>(2020-12-07, 1)</td>\n",
              "      <td>(2020-12-07, 3)</td>\n",
              "      <td>(2020-12-07, 4)</td>\n",
              "      <td>(2020-12-07, 0)</td>\n",
              "      <td>(2020-12-07, 2)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320</th>\n",
              "      <td>(2020-12-08, 1)</td>\n",
              "      <td>(2020-12-08, 3)</td>\n",
              "      <td>(2020-12-08, 4)</td>\n",
              "      <td>(2020-12-08, 0)</td>\n",
              "      <td>(2020-12-08, 2)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321</th>\n",
              "      <td>(2020-12-09, 1)</td>\n",
              "      <td>(2020-12-09, 3)</td>\n",
              "      <td>(2020-12-09, 4)</td>\n",
              "      <td>(2020-12-09, 0)</td>\n",
              "      <td>(2020-12-09, 2)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>322 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      school-closing workplace-closing  ... public-transport international-travel\n",
              "0    (2020-01-23, 0)   (2020-01-23, 0)  ...  (2020-01-23, 0)      (2020-01-23, 0)\n",
              "1    (2020-01-24, 0)   (2020-01-24, 0)  ...  (2020-01-24, 0)      (2020-01-24, 0)\n",
              "2    (2020-01-25, 0)   (2020-01-25, 0)  ...  (2020-01-25, 0)      (2020-01-25, 0)\n",
              "3    (2020-01-26, 0)   (2020-01-26, 0)  ...  (2020-01-26, 0)      (2020-01-26, 0)\n",
              "4    (2020-01-27, 0)   (2020-01-27, 0)  ...  (2020-01-27, 0)      (2020-01-27, 0)\n",
              "..               ...               ...  ...              ...                  ...\n",
              "317  (2020-12-05, 1)   (2020-12-05, 3)  ...  (2020-12-05, 0)      (2020-12-05, 2)\n",
              "318  (2020-12-06, 1)   (2020-12-06, 3)  ...  (2020-12-06, 0)      (2020-12-06, 2)\n",
              "319  (2020-12-07, 1)   (2020-12-07, 3)  ...  (2020-12-07, 0)      (2020-12-07, 2)\n",
              "320  (2020-12-08, 1)   (2020-12-08, 3)  ...  (2020-12-08, 0)      (2020-12-08, 2)\n",
              "321  (2020-12-09, 1)   (2020-12-09, 3)  ...  (2020-12-09, 0)      (2020-12-09, 2)\n",
              "\n",
              "[322 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJk2FszQAmhc"
      },
      "source": [
        "import torch\n",
        "\n",
        "# Use GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCzPs0hUCFcP"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# Define the model\n",
        "class BiLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, seq_len=1, batch_size=1):\n",
        "        super(BiLSTM, self).__init__()\n",
        "\n",
        "        # Number of features\n",
        "        self.input_size = input_size\n",
        "\n",
        "        # Number of features in hidden state\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # Number of stacked recurrent layers\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # Size of each input sequence \n",
        "        self.seq_len = seq_len\n",
        "        self.batch_size = batch_size\n",
        "        \n",
        "        # We use a bidirectional LSTM to continuously update older predictions\n",
        "        # based on newer data, which will hopefully improve accuracy by using\n",
        "        # greater context.\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size,\n",
        "            hidden_size,\n",
        "            num_layers,\n",
        "            bidirectional=True,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # The input to the linear layer will be the output of the LSTM.\n",
        "        # Since we are using a bidirectional LSTM, we will have both the outputs\n",
        "        # of the forward-LSTM and the backward-LSTM concatenated, which we will then\n",
        "        # use to create our prediction. This is why the input size is twice the\n",
        "        # size of the hidden output dimension. Our output size is 1 since we are\n",
        "        # performing regression, and need a single value.\n",
        "        self.fc = nn.Linear(hidden_size * 2, 1)\n",
        "        \n",
        "    def init_hidden(self):\n",
        "        return (torch.zeros(self.num_layers * 2, self.batch_size, self.hidden_size).to(device),\n",
        "            torch.zeros(self.num_layers * 2, self.batch_size, self.hidden_size).to(device))\n",
        "    \n",
        "    def forward(self, x, hidden):\n",
        "        out, (hn, cn) = self.lstm(x.view(self.batch_size, self.seq_len, self.input_size), hidden)\n",
        "        return self.fc(out.view(-1, self.batch_size, self.hidden_size * 2)), (hn.detach(), cn.detach())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SC_PP-J0OaNj"
      },
      "source": [
        "Next we define a dataset class inheriting from `torch.utils.data.Dataset`, which will make loading data for training a cleaner and easier process. Our data consists of various relevant features, including:\n",
        " \n",
        "\n",
        "*   The current day's Twitter sentiment related to COVID-19\n",
        "*   The number of confirmed COVID-19 cases\n",
        "*   The number of \n",
        "\n",
        "COVID-19, the number of confirmed COVID-19 cases, the number of"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxu31zlLOulZ"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CovidDataset(Dataset):\n",
        "    def __init__(self, data, targets):\n",
        "        self.data = data\n",
        "        self.targets = targets\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return torch.FloatTensor(self.data[idx]).to(device), \\\n",
        "            torch.FloatTensor([self.targets[idx]]).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ME2IcMqXsOT",
        "outputId": "ad50011f-674e-449d-fba0-a867de3050ed"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Set seed to ensure our results are reproducible\n",
        "np.random.seed(42)\n",
        "\n",
        "# Read data\n",
        "df = pd.read_csv('canada-covid-data.csv', usecols=['location', 'total_cases'])\n",
        "df = df[df['location'] == 'Canada']\n",
        "dataset = np.array(df['total_cases'].dropna().values)\n",
        "dataset = np.expand_dims(dataset, axis=1)\n",
        "\n",
        "# Since LSTMs are sensitive to the scale of the input data,\n",
        "# we normalize the inputs:\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "dataset = scaler.fit_transform(dataset)\n",
        "\n",
        "dataset = np.expand_dims(dataset, axis=1)\n",
        "print(dataset.shape)\n",
        "\n",
        "# Split the data into train and test sets\n",
        "train_size = int(len(dataset) * 0.75)\n",
        "test_size = len(dataset) - train_size\n",
        "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(319, 1, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pltUooYxgLmP"
      },
      "source": [
        "Our input data will be a sequence of values, and our output will be the single value for the cumulative COVID-19 cases. Given input data $\\{x_1, x_2, ..., x_{n-1}\\}$ and output data $\\{y_1, y_2, ..., y_n\\}$, if we would like to predict a value $y_i$, we will use a sequence $x_{i-k-1},...,x_{i-1}$ to make the prediction. For this purpose, we have defined the `create_dataset` method to reshape the data in this format, where `look_back` corresponds to $k$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQGQ98ANfrY0"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def create_dataset(dataset, look_back=1):\n",
        "    data_x, data_y = [], []\n",
        "    for i in range(len(dataset) - look_back-1):\n",
        "        a = dataset[i:(i+look_back), 0]\n",
        "        data_x.append(a)\n",
        "        data_y.append(dataset[i + look_back, 0])\n",
        "    return np.array(data_x), np.array(data_y)\n",
        "\n",
        "look_back = 6\n",
        "train_x, train_y = create_dataset(train, look_back)\n",
        "test_x, test_y = create_dataset(test, look_back)\n",
        "\n",
        "train_loader = DataLoader(CovidDataset(train_x, train_y), shuffle=False)\n",
        "test_loader = DataLoader(CovidDataset(test_x, test_y), shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u60g3bILi39a"
      },
      "source": [
        "Now that our data is formatted we will create the model and perform the training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXM2OC7qi9pE"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "epochs = 100\n",
        "batch_size = 1\n",
        "num_layers = 2\n",
        "input_size = train_x.shape[2]\n",
        "hidden_size = 256\n",
        "\n",
        "model = BiLSTM(input_size, hidden_size, num_layers, look_back, batch_size=1)\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "9P_zZWkfkX1M",
        "outputId": "d2f4ac53-2f78-46e0-a429-1621878e942f"
      },
      "source": [
        "train_mse = []\n",
        "test_mse = []\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    hidden = model.init_hidden()\n",
        "    train_loss_tot = 0\n",
        "    train_ctr = 0\n",
        "    for i, (data, target) in enumerate(train_loader):\n",
        "        train_ctr += 1\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward\n",
        "        prediction, hidden = model(data, hidden)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(prediction, target.squeeze())\n",
        "\n",
        "        # Backpropagate\n",
        "        loss.backward()\n",
        "\n",
        "        # Perform Adam step\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss_tot += loss.item()\n",
        "\n",
        "    train_mse += [train_loss_tot / train_ctr]\n",
        "\n",
        "    hidden = model.init_hidden()\n",
        "    test_loss_tot = 0\n",
        "    test_ctr = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (data, target) in enumerate(test_loader):\n",
        "            test_ctr += 1\n",
        "\n",
        "            # Calculate prediction\n",
        "            prediction, hidden = model(data, hidden)\n",
        "            \n",
        "            # Calculate loss\n",
        "            loss = criterion(prediction, target.squeeze())\n",
        "\n",
        "            test_loss_tot += loss.item()\n",
        "    \n",
        "    test_mse += [test_loss_tot / test_ctr]\n",
        "    print('[INFO] epoch: {}, train MSE: {:.5f}, test MSE: {:.5f}'.format(epoch, train_mse[-1], test_mse[-1]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([6, 1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO] epoch: 0, train MSE: 0.00025, test MSE: 0.09050\n",
            "[INFO] epoch: 1, train MSE: 0.00080, test MSE: 0.10920\n",
            "[INFO] epoch: 2, train MSE: 0.00113, test MSE: 0.10763\n",
            "[INFO] epoch: 3, train MSE: 0.00123, test MSE: 0.10974\n",
            "[INFO] epoch: 4, train MSE: 0.00134, test MSE: 0.10504\n",
            "[INFO] epoch: 5, train MSE: 0.00138, test MSE: 0.10742\n",
            "[INFO] epoch: 6, train MSE: 0.00135, test MSE: 0.10493\n",
            "[INFO] epoch: 7, train MSE: 0.00136, test MSE: 0.10686\n",
            "[INFO] epoch: 8, train MSE: 0.00129, test MSE: 0.10312\n",
            "[INFO] epoch: 9, train MSE: 0.00133, test MSE: 0.10434\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-145-dfdb5ca3085d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Perform Adam step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mtrain_loss_tot\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    117\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m                    )\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}